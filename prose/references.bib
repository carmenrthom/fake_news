@ARTICLE{9395133,
  author={Verma, Pawan Kumar and Agrawal, Prateek and Amorim, Ivone and Prodan, Radu},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={WELFake: Word Embedding Over Linguistic Features for Fake News Detection}, 
  year={2021},
  volume={8},
  number={4},
  pages={881-893},
  keywords={Social networking (online);Linguistics;Data models;Bit error rate;Feature extraction;Training;Vegetation;Bidirectional encoder representations from transformer (BERT);convolutional neural network (CNN);fake news;linguistic feature;machine learning (ML);text classification;voting classifier;word embedding (WE)},
  doi={10.1109/TCSS.2021.3068519}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Verma_2023, title={How AI fake news is creating a ‘misinformation superspreader’}, url={https://www.washingtonpost.com/technology/2023/12/17/ai-fake-news-misinformation/}, journal={The Washington Post}, author={Verma, Pranshu}, year={2023}, month={Dec}
} 